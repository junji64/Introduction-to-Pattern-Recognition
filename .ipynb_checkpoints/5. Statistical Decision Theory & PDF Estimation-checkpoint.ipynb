{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계적 결정이론 및 확률밀도함수 추정\n",
    "\n",
    "## 우도비검증 (Likelihood Ratio Test : LRT)\n",
    "\n",
    "### 데이타의 확률밀도함수를 알 경우의 클래스의 분류\n",
    "\n",
    "임의의 대상체의 측정 (특징 벡터) $x$ 에 주어진 증거에 따라서 분류하는 문제를 생각해보자.\n",
    "* \"관찰된 특징벡터 $x$ 에 주어진 가장 그럴듯한 클래스로 분류\" 또는\n",
    "* \"각 클래스의 사후확률 $P(\\omega_i|x)$ 을 계산하여 그 중 가장 큰 값을 가지는 클래스로 결정\"\n",
    "\n",
    "여기에서, 사후확률 $P(\\omega_i|x)$ 은 사전확률 $P(\\omega_i)$ 와 우도 $P(x|\\omega_i)$ 의 곱으로 대치하여 계산하며, 이 때 사전확률 $P(\\omega_i)$는 샘플의 수가 $N$ 이라 하고 $\\omega_i$ 에 속하는 샘플 수를 $N_i$ 라 하면, $P(\\omega_i) = N_i/N$ 로 추정하면 된다 (이는, 샘플의 개수가 충분히 크면 실제 확률값에 매우 근접하게 된다.)\n",
    "\n",
    "$$ \\text{if } P(\\omega_1 | x) > P(\\omega_2 | x) \\text{ choose } \\omega_1 \\text{ else choose } \\omega_2$$\n",
    "$$ P(\\omega_1 | x) \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} P(\\omega_2 | x) $$\n",
    "\n",
    "$$ {P(x|\\omega_1) P(\\omega_1) \\over P(x) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} {P(x|\\omega_2) P(\\omega_2) \\over P(x) } $$\n",
    "\n",
    "$$ \\text{ 우도비(Likelihood Ratio) } \\Rightarrow \\Lambda(x) =  {P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { P(\\omega_2) \\over  P(\\omega_1)  } $$\n",
    "\n",
    "따라서, 만약에 두 클래스의 사전확률이 같을 경우, 특정 클래스로 결정은 우도비 만으로 가능하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Ex) \n",
    "다음과 같이 두 클래스 $\\omega_1$, $\\omega_2$ 가 주어진 경우 (조건부) 확률밀도함수 (우도함수)가 주어질 경우, LRT 결정 규칙을 유도해 보자. 단, 사전확률은 같다고 가정한다.\n",
    "\n",
    "$$ P(x|\\omega_1) = { 1 \\over \\sqrt{2\\pi}} e^{-{1 \\over 2} (x-4)^2}$$\n",
    "$$ P(x|\\omega_2) = { 1 \\over \\sqrt{2\\pi}} e^{-{1 \\over 2} (x-10)^2}$$\n",
    "\n",
    "Remember\n",
    "$$  \\Lambda(x) =  {P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { P(\\omega_2) \\over  P(\\omega_1)  } $$\n",
    "\n",
    "$$  \\Lambda(x) = { { 1 \\over \\sqrt{2\\pi}} e^{-{1 \\over 2} (x-4)^2} \\over { 1 \\over \\sqrt{2\\pi}} e^{-{1 \\over 2} (x-10)^2} }  \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 1 \\over 1 }$$\n",
    "\n",
    "$$  \\Lambda(x) = {  e^{-{1 \\over 2} (x-4)^2} \\over e^{-{1 \\over 2} (x-10)^2} }  \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 1}$$\n",
    "\n",
    "양변에 $\\log()$ 를 취하면,\n",
    "\n",
    "$$  (x-4)^2 - (x-10)^2   \\overset{\\omega_1}{\\underset{\\omega_2}{\\lessgtr}} { 0}$$\n",
    "\n",
    "$$  x   \\overset{\\omega_1}{\\underset{\\omega_2}{\\lessgtr}} { 7}$$\n",
    " \n",
    "<img src=\"images/LRT-ex.png\" width=\"300\">\n",
    "\n",
    "* 만약 사전확률이 $P(\\omega_1) = 2 P(\\omega_2)$ 와 같다면, LRT 결정규칙은 어떻게 바뀔까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오류확률(Probability of Error)\n",
    "\n",
    "분류기를 “특징공간을 결정영역으로 분할하는 장치”라고 생각하면, 베이즈 분류기에서 몇 가지 부가적인 통찰을 할 수 있다. 두 개의 클래스가 주어진 경우, 베이즈 분류기를 이용하여 특징공간을 두 영역 $(R_1,R_2)$ 으로 분할할 때, 잘못 분류되는 경우는 다음과 같은 두 가지가 있을 것이다. \n",
    "\n",
    "1. $\\omega_1$에 속하는 특징벡터 $x$를 $R_2$로 결정할 경우, \n",
    "2. $\\omega_2$에 속하는 특징벡터 $x$를 $R_1$로 결정할 경우. \n",
    "\n",
    "오류 사건은 상호 배타적이므로 총 오류 발생 확률은 다음과 같이 표현된다.\n",
    "\n",
    "$$ P[\\text{error}] = \\sum_{i=1}^{2} P[\\text{error} | \\omega_i] P[\\omega_i] $$\n",
    "\n",
    "총 오류확률에서 주어진 각 클래스에서 생기는 오류확률은 다음과 같이 표현되고 \n",
    "\n",
    "$$ P[\\text{error} | \\omega_i] =  P[ \\text{choose } \\omega_j | \\omega_i] = \\int_{R_j} P(x|\\omega_i) dx $$\n",
    "\n",
    "따라서 두 클래스에 대한 오류 확률은 다음과 같다.\n",
    "\n",
    "$$ P[\\text{error}] = P[\\omega_1] \\underset{\\epsilon_1}{\\underbrace{\\int_{R_2}P(x | \\omega_1)dx}} +  P[\\omega_2] \\underset{\\epsilon_2}{\\underbrace{\\int_{R_1}P(x | \\omega_2)dx}} $$\n",
    "\n",
    "여기서, $\\epsilon_i$ 는 선택한 $\\omega_j$ 의 영역 $R_j$ 상에서 $P[x|\\omega_i]$ 를 적분한 값이므로 앞에서 살펴본 결정 규칙과 같이 오류확률 $P[error]$ 의 사전 확률이 0.5로 같다고 가정하면, 총 오류 확률은 $\\epsilon_1$ 와 $\\epsilon_2$ 의 항으로 다음과 같이 표현된다.\n",
    "\n",
    "$$ P[\\text{error}] = (\\epsilon_1 + \\epsilon_2) / 2 $$\n",
    "\n",
    "<img src=\"images/error-ex.png\" width=\"300\">\n",
    "\n",
    "LRT 결정규칙의 정확도를 알기 위해서, 오류확률을 통한 결정경계의 결정을 고려해 보자. \n",
    "* 어떤 $x$가 주어진 경우의 오류확률 $P[error]$은 사후 확률 $P[error|x]$로 표현하면, \n",
    "\n",
    "$$ P[\\text{error}] =  \\int_{-\\infty}^{+\\infty} P[\\text{error}|x]P(x) dx $$\n",
    "\n",
    "“최적의 결정경계 = 최소오류확률 “ 이므로 위의 적분이 최소화 되어야 함\n",
    "\n",
    "주어진 점 $x$’에서, $P[error|x’]$는 다른 클래스 $\\omega_j$ 를 선택한 경우의 $P[\\omega_i |x’]$로서 다음의 그림과 같이 주어진다.  그림으로부터 어떤 $x’$이던 간에 LRT 결정 규칙이 항상 낮은 $P[error|x’]$를 가지며, 따라서 적분을 해도 항상 더 낮은 $P[error]$을 갖게 됨을 알 수 있다.\n",
    "\n",
    "<img src=\"images/error-ex2.png\" width=450>\n",
    "\n",
    "\n",
    "어느 문제에서든, 최소 오류 확률은 LRT 결정규칙에 의해서 얻어진다. 이러한 오류 확률을 베이즈 오류율(Bayes Error Rate)이라고 하며 최고의 분류기 가 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이즈 위험(Bayes Risk)\n",
    "베이즈 위험의 의미 : 패턴 분류기가 잘못 분류하여 발생하는 비용($C_{ij}$)의 개념을 베이즈 분류기에 적용한 비용의 기대값, $\\mathscr{R}=E[C]$, ( 여기서 $C_{ij}$ 는 실제로 $\\omega_j$ 인 클래스를 $\\omega_i$ 클래스로 분류했을 때 의 비용을 말함)\n",
    "\n",
    "$$ \\mathscr{R} = E[C] = \\sum_{i=1}^2\\sum_{j=1}^2 C_{ij}\\cdot P[\\text{choose } \\omega_i \\text{ and } x \\in \\omega_j ] = \\sum_{i=1}^2\\sum_{j=1}^2 C_{ij}\\cdot P[x \\in R_i | \\omega_j ] \\cdot P[\\omega_j] $$ \n",
    "\n",
    "베이즈 위험을 최소화하는 결정규칙은 우선 다음과 같은 관계를 이용하면\n",
    "\n",
    "$$  P[x \\in R_i | \\omega_j ] \\cdot P[\\omega_j] = \\int_{R_i} P(x|\\omega_j)dx $$\n",
    "\n",
    "베이즈 위험은 다음과 같이 표현이 된다\n",
    "$$ \\mathscr{R} = \\int_{R_1} \\left [ C_{11}\\cdot P[\\omega_1]\\cdot P(x|\\omega_1) + C_{12}\\cdot P[\\omega_2]\\cdot P(x|\\omega_2) \\right] dx + \\int_{R_2} \\left[ C_{21}\\cdot P[\\omega_1]\\cdot P(x|\\omega_1) + C_{22}\\cdot P[\\omega_2]\\cdot P(x|\\omega_2)\\right] dx$$\n",
    "\n",
    "그리고, 우도(likelihood)를 다음과 같이 표현이 가능하므로\n",
    "$$ \\int_{R_1}  P(x|\\omega_i)dx +  \\int_{R_2}  P(x|\\omega_i)dx =  \\int_{R_1 \\cup  R_2}  P(x|\\omega_i) dx = 1 $$ \n",
    "\n",
    "$$ \\mathscr{R} = C_{11} P[\\omega_1] \\int_{R_1} P(x|\\omega_1)dx + \n",
    " C_{12} P[\\omega_2] \\int_{R_1} P(x|\\omega_2)dx \\\\\n",
    " +  C_{21} P[\\omega_1] \\int_{R_2} P(x|\\omega_1)dx \n",
    " +  C_{22} P[\\omega_2] \\int_{R_2} P(x|\\omega_2)dx \\\\\n",
    " + C_{21} P[\\omega_1] \\int_{R_1} P(x|\\omega_1)dx \n",
    " + C_{22} P[\\omega_2] \\int_{R_1} P(x|\\omega_2)dx \\\\\n",
    " - C_{21} P[\\omega_1] \\int_{R_1} P(x|\\omega_1)dx \n",
    " - C_{22} P[\\omega_2] \\int_{R_1} P(x|\\omega_2)dx $$\n",
    " \n",
    "여기에서, 마지막 두 행은 추가된 항으로, 같은 값을 더하고 빼주었으므로 원래의 식에는 변화가 없게 된다. $R_2$에 대한 적분을 제거하면  (우도에 대한 표현를 이용하여) \n",
    "\n",
    "$$ \\mathscr{R} = C_{21} P[\\omega_1]+C_{22} P[\\omega_2] \\\\\n",
    "+ (C_{12}-C_{22}) P[\\omega_2] \\int_{R_1} P(x|\\omega_2)dx\n",
    "- (C_{21}-C_{11}) P[\\omega_1] \\int_{R_1} P(x|\\omega_1)dx $$\n",
    "\n",
    "첫 번째 두 항은 상수이므로, 우리는 다음을 최소화하는 결정영역 $R_1$ 을 찾게 된다. \n",
    "\n",
    "$$ R_1 = \\text{argmin} \\{ \\int_{R_1} [ (C_{12}-C_{22}) P[\\omega_2] P(x|\\omega_2)\n",
    "- (C_{21}-C_{11}) P[\\omega_1] P(x|\\omega_1) ]\\}dx\n",
    "\\\\\n",
    "=  \\text{argmin} \\{ \\int_{R_1}g(x) dx \\}$$\n",
    "\n",
    "이제 우리가 찾고 있는 결정영역 $R_1$에 대한 이해를 좀 더 확장하기 위해서 $g(x)$로 치환하여 간략화 한다. 결국 적분  $\\int_{R_1} g(s)dx$ 를 최소화하는 영역 R1을 선택하는 문제로서 $g(x) < 0$ 인 영역을 $R_1$ 에 속하는 영역으로 선택하게 된다.\n",
    "\n",
    "<img src=\"images/BayesRisk.png\" width=350>\n",
    "\n",
    "치환된 g(x) 를 풀면\n",
    "\n",
    "$$ (C_{21} - C_{11}) P[\\omega_1] P(x | \\omega_1) \\overset{\\omega_1}{>} (C_{12} - C_{22}) P[\\omega_2] P(x | \\omega_2) $$\n",
    "\n",
    "이를 다시 정리하면\n",
    "\n",
    "$${P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { (C_{21} - C_{11})P(\\omega_2) \\over (C_{12} - C_{22}) P(\\omega_1)  } $$\n",
    "\n",
    "결국, 베이즈 위험의 최소화를 통해서도 결정 경계를 결정할 수 있으며 우도비 검증 (LRT)이 됨을 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Ex) 베이즈 위험을 최소화하는 결정규칙** \n",
    "\n",
    "다음과 같이 두 클래스 우도함수가 주어질 경우, 분류 문제를 고려해보자\n",
    "\n",
    "$$ P(x|\\omega_1) = { 1 \\over \\sqrt{2\\pi} \\sqrt{3}} e ^{-{1 \\over 2}{ x^2 \\over 3}} $$\n",
    "$$ P(x|\\omega_2) = { 1 \\over \\sqrt{2\\pi}} e ^{-{1 \\over 2}(x-2)^2 } $$\n",
    "\n",
    "<img src=\"images/BayesRisk-ex1.png\" width=\"250\">\n",
    "\n",
    "$P[\\omega_1] = P[\\omega_2] = 0.5, C_{11}=C_{22} = 0, C_{12}=1, C_{21}=\\sqrt{3} $ 라고 가정하고, 베이즈위험이 최소화 되는 결정 규칙을 결정하시오.\n",
    "\n",
    "$$  \\Lambda(x) = { { 1 \\over \\sqrt{2\\pi} \\sqrt{3}} e^{-{1 \\over 2} {x^2 \\over 3}} \\over { 1 \\over \\sqrt{2\\pi}} e^{-{1 \\over 2} (x-2)^2} }  \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 1 \\over \\sqrt{3} }$$\n",
    "\n",
    "$$  \\Lambda(x) = {  e^{-{1 \\over 2} {x^2 \\over 3}} \\over e^{-{1 \\over 2} (x-2)^2} }  \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 1}$$\n",
    "\n",
    "양변에 $\\log()$를 취하면.\n",
    "\n",
    "$$ -{ 1 \\over 2}{ x^2 \\over 3} + { 1 \\over 2} (x-2)^2   \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 0}$$\n",
    "\n",
    "$$ 2x^2 - 12 x + 12    \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { 0} \\Rightarrow x = 4.73, 1.27 $$\n",
    "\n",
    "<img src=\"images/BayesRisk-ex2.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LRT 결정규칙의 변형\n",
    "1. 베이즈 위험(Bayes Risk)을 최소화하는 LRT결정규칙을 **Bayes Criterion(베이즈 규준)** 이라고 정의한다.\n",
    "\n",
    "$$\\Lambda(x) = {P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { (C_{12} - C_{22})P[\\omega_2] \\over (C_{21} - C_{11}) P[\\omega_1]  } \\Leftarrow \\text{ Bayes criterion} $$\n",
    "\n",
    "2. 대칭적 혹은 비용 값이 0 또는 1인 제로-원 비용함수를 사용하면 베이즈 규준이 사후확률($P(\\omega_i|x)$)의 비로 표현된다. 이 규준을 사후 확률 최대화한다는 의미에서 “**MAP(Maximum A Posteriori) 규준**”이라고 한다.\n",
    "\n",
    "$$ C_{ij} =\n",
    "  \\begin{cases}\n",
    "    0  &  i=j\\\\\n",
    "    1  &  i\\ne j\n",
    "  \\end{cases}\n",
    "  \\Rightarrow \n",
    "\\Lambda(x) = {P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} { P[\\omega_2] \\over  P[\\omega_1]  } \\Leftrightarrow {P(\\omega_1|x)\\over P(\\omega_2|x) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} {1 } \\Leftarrow\n",
    "\\text{ Maximum A Posteriori (MAP) Criterion} $$\n",
    "\n",
    "3. 사전확률($P(\\omega_i)$)이 같고 제로-원 비용함수의 경우, 베이즈 규준은 우도 $P(x|\\omega_i)$ 의 비로 표현된다. 이 규준을 우도를 최대화한다는 의미에서 **ML(Maximum Likelihood) 규준**이라고 한다.\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "C_{ij} =\n",
    " \\begin{cases}\n",
    "    0  &  i=j\\\\\n",
    "    1  &  i\\ne j\n",
    "  \\end{cases} \\\\\n",
    "P(\\omega_i)= {1 \\over C} \\quad \\forall i\n",
    "\\end{cases}\n",
    "\\Rightarrow \n",
    "\\Lambda(x) = {P(x|\\omega_1)\\over P(x|\\omega_2) } \\overset{\\omega_1}{\\underset{\\omega_2}{\\gtrless}} 1 \\Leftarrow\n",
    "\\text{ Maximum Likelihood (ML) Criterion} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중클래스결정규칙\n",
    "\n",
    "#### (1) 최소오류확률을 이용한 다중클래스 결정규칙\n",
    "\n",
    "최소오류확률 $P[\\text{error}]$을 최소화하는 결정규칙은 다중클레스 결정문제로 쉽게 일반화 될 수 있다. $P[\\text{error}]=1-P[\\text{correct}]$로부터, “$P[\\text{error}]$를 최소화”하는 문제는“$P[\\text{correct}]$를 최대화”하는 것과 같다. 아래의 식은 $P[\\text{correct}]$를 사후확률의 형태로 표현해 본 결과이다\n",
    "\n",
    "$$ P[\\text{correct}] = \\sum_{i=1}^C P(\\omega_i) \\int_{R_i} P(x|\\omega_i) dx =  \n",
    "\\sum_{i=1}^C \\int_{R_i}  P(x|\\omega_i)  P(\\omega_i) dx =\n",
    "\\sum_{i=1}^C \\int_{R_i}  P(\\omega_i|x)  P(x) dx$$\n",
    "\n",
    "$$\\because \\text{결합확률} : P[B]P[A|B] = P(A\\cap B) = P[A] P[B|A]$$\n",
    "\n",
    "$P[\\text{correct}]$ 를 최대화하기 위해서는 각각의 적분을 최대화해야하며, 각각의 적분은 최대 $P(\\omega_i|x)$를 갖는($p[x]$는 일정하므로) 클래스 $\\omega_i$ 를 선택해야 하고, 따라서 $P(\\omega_i|x)$가 최대가 되는 영역 $R_i$를 정의하게 된다.\n",
    "따라서, $P[\\text{error}]$를 최소화하는 결정규칙은 MAP(Maximum A Posteriori) 규준에 해당한다.\n",
    "\n",
    "<img src=\"images/multi-class-bayes-error.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 베이즈 위험을 이용한 다중 클래스 결정규칙\n",
    "다중 클래스 문제에 대한 베이즈 위험을 최소화하는 결정 규칙은 약간 다른 수식을 사용하여 유도한다. 먼저, 클래스 $\\omega_i$ 를 선택하는 결정을 $\\alpha_i$ 라고 정의하고, 특징 $x$ 를 클래스 $\\omega_i$\n",
    "로 매핑하는 전체 결정규칙을 $\\alpha(x)$ 라고 정의한다. 즉, $\\alpha(x) \\rightarrow \\{ \\alpha_1, \\alpha_2, …, \\alpha_c \\}$. 특징 $x$ 를 클래스  $\\omega_i$  로 할당하는 (조건적) 베이즈 위험 $ R(\\alpha_i|x)$ 은 다음과 같이 표현된다.\n",
    "\n",
    "$$\\mathscr{R}(\\alpha(x) \\rightarrow \\alpha_i) = \\mathscr{R}(\\alpha_i |x) = \\sum_{j=1}^C C_{ij} P (\\omega_j | x) $$\n",
    "\n",
    "그리고 전체 결정 규칙 $\\alpha(x)$과 관련된 베이즈 위험은 다음과 같이 표현된다.\n",
    "\n",
    "$$\\mathscr{R}(\\alpha(x)) = \\int \\mathscr{R}(\\alpha(x) |x) P(x) dx $$\n",
    "\n",
    "이 표현식이 최소화 되기 위해서는 특징공간 상의 각 점 $x$ 에서 베이즈 위험$ R(\\alpha (x)|x)$ 이 최소화 되어야 한다. 즉, $ R(\\alpha_i|x)$ 이 최소인 $\\omega_i$ 를 선택하는 것과 같다.\n",
    "\n",
    "<img src=\"images/multi-bayes-risk.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 판별함수\n",
    "\n",
    "이 장에서 설명한 모든 결정 규칙들은 동일한 구조를 갖고 있다. 이러한 구조는 분류기준함수의 집합 $ g_i(x), i=1,\\cdots,x$ 에 대하여 다음과 같이 정리될 수 있다.\n",
    "\n",
    "만약, $g_i(x) > g_j(x) \\quad \\forall j\\ne i$ 이라면, **특징벡터 $x$를 클래스 $\\omega_i$** 에 속한다고 결정. \n",
    "\n",
    "따라서, $C$ 개의 클래스 중의 하나로 결정하는 시스템은 $C$ 개의 판별함수로 구성된 네트워크로 표현하는 가장 큰 값을 출력하는 카테고리를 선택하는 구조를 가진다.\n",
    "\n",
    "<img src=\"images/discr-func.png\" width=450>\n",
    "\n",
    "\n",
    "| criterion | Discriminant Function |\n",
    "|-----------|-----------------------|\n",
    "| Bayes     | $g_i(x) = -\\mathscr{R}(\\alpha_i | x)$ |\n",
    "| MAP       | $g_i(x) = P(\\omega_i | x)$ |\n",
    "| ML        | $g_i(x) = P(x | \\omega_i) $ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최우추정법에 의한 확률밀도함수의 추정\n",
    "\n",
    "지금까지는 **확률밀도가 주어진 경우**에 영역 결정과 분류기를 어떻게 만드는 지를 설명하였다. 하지만, 대부분의 경우 **실제 확률밀도분포에 대한 지식은 입수 할 수 없으며**, 실험자료로부터 결정되어야 한다. 이 때에는 두 가지 접근법이 일반적이다.\n",
    "\n",
    "1. **파라미타 추정 (Parameter Estimation)법** : 밀도에 대하여 특정한 형태를 가정하여 (e.g.가우시안) 이를 결정짖는 파라미터들 (e.g. 평균과 분산)을 최대우도추정 (Maximum Likelihood Estimation) 방법을 통해서 결정한다.\n",
    "\n",
    "2. **비모수 밀도 추정 (Non-parametric Density Estimation)법** : 밀도에 대하여 어떠한 지식도 가정하지 않는 방법으로, 커널밀도 추정법 또는 최근접이웃 규칙법 등이 있다. \n",
    "\n",
    "**최우추정 (Maximum Likelihood Estimation:MLE)** 이란?: \n",
    "\n",
    "“주어진 자료 $X$를 발생시켰을 가능성이 가장 높은 매개 변수 $\\theta$를 찾아라.”\n",
    "\n",
    "즉, 주어진 자료 $X$에 대해 가장 큰 우도를 갖는 $\\theta$를 찾는 것과 같다.  아래의 그림과 같은 예에서 : \n",
    "\n",
    "$$P(X| \\theta_1) > P(X|\\theta_2)$$\n",
    " \n",
    " \n",
    "<img src=\"./images/ML-1.png\" width=\"300\">\n",
    "\n",
    "최대 우도를 갖는 $\\theta$ 는? 파라미터들이 고정되어 있으나 모른다고 가정한다. 최우추정 해는 다음과 같이 자료 $X$를 가장 잘 설명하는 해를 구한다.\n",
    "\n",
    "$$ \\hat{\\theta} = \\arg\\max[p(X|\\theta)] $$\n",
    " \n",
    "<img src=\"./images/ML-2.jpg\" width=\"250\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최대 우도 추정 (최우추정, MLE : Maximum Likelihood Estimation)**\n",
    "\n",
    "일련의 파라미터들 $\\theta=[\\theta_1, \\theta_2, …, \\theta_N]^T$ 으로 구성된 어떤 확률밀도함수 $p(x|\\theta)$ 로부터 관측된 표본 데이터 집합을 $X={x^{(1},x^{(2},…,x^{(N}}$ 라 할 때, \n",
    "이 표본들로부터 파라미터 $\\theta=[\\theta_1, \\theta_2, …, \\theta_N]^T$  들을 추정하는 문제를 생각해보자. (즉, 평균, $\\mu_0$, 와 분산,$\\sigma_0^2$ 를 갖는 가우시안 확률분포로부터 관측된 표본데이터로부터 평균과 분산을 추정하는 문제). 어떤 표본 집합이 특정한 확률밀도 함수 $p(x|\\theta)$ 로 표현되는 프로세스로부터 발생한 데이터로 이루어져 있다면, 전체 표본 집합은 결합확률밀도로 다음과 같이 표현된다.\n",
    "\n",
    "$$ p(X|\\theta) = p(x^{(1} | \\theta) p(x^{(2} | \\theta) \\cdots p(x^{(N} | \\theta) = \\prod_{k=1}^N p(x^{(k} | \\theta) $$\n",
    "\n",
    "그런데, 이 함수는 확률함수이므로 가장 큰 확률 값을 발생시키는 $\\theta$ 값을 추정값  $\\hat{\\theta}$    으로 보는 것이 가장 그럴듯할 것이다. 이는 자료를 가장 그렇게 줄 수 있는 θ 값을 얻는 직관적인 생각에 해당한다. 여기서, $p(x|\\theta)$ 는 파라미터 $\\theta$  에 따르는 주어진 데이터 집합의 우도(likelihood) 함수이다. 우도 함수의 곱을 합으로 하기 위해서 로그를 취하면 다음과 같이 된다.\n",
    "\n",
    "$$ \\hat{\\theta} = \\arg\\max[p(X|\\theta)] = \\arg\\max[\\log p(X|\\theta)]$$\n",
    "\n",
    "$$ \\hat{\\theta} = \\arg\\max[\\log \\prod_{k-1}^N p(x^{(k}|\\theta)] = \\arg\\max[ \\sum_{k-1}^N \\log p(x^{(k}|\\theta)]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**로그-우도를 사용하는 이유**\n",
    "\n",
    "분석을 위해서는 우도의 로그를 갖고 일하는 것이 편리하다. 로그는 단조함수(monotonic function: 단조증가함수와 단조감소함수의 총칭 ) 이므로\n",
    "\n",
    "<img src=\"images/log-ML.png\" width=\"550\">\n",
    "\n",
    "로그를 취하면 파라미터의 최우추정은 다음과 같이 되어\n",
    "\n",
    "$$ \\hat{\\theta} = \\arg\\max[\\log \\prod_{k-1}^N p(x^{(k}|\\theta)] = \\arg\\max[ \\sum_{k-1}^N \\log p(x^{(k}|\\theta)]  $$\n",
    "\n",
    "\n",
    "* 항들의 합을 최대화 시키는 것은 곱을 최대화 시키는 것보다 쉬운 일이며  (항들의 곱들에 대한 미분을 생각해 보면 알 수 있음), \n",
    "* 분포가 가우시안이면 로그를 취하는 것의 장점이 더 명확해진다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**단변량 가우시안의 경우**: \n",
    "\n",
    "확률밀도함수가 $p(x) = \\mathscr{N}(\\mu, \\sigma)$ 로 주어진 자료 $X=\\{x^{(1},x^{(2},…,x^{(N}\\}$ 에서 표준편차 $\\sigma$ 가 주어진 경우, 평균의 최우추정은?\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\theta} & = \\arg\\max \\sum_{k=1}^N \\log p(x^{(k} | \\theta) \\\\\n",
    "             & = \\arg\\max \\sum_{k=1}^N \\log \\left( {1 \\over \\sqrt{2\\pi} \\sigma} \\exp \\left( - {1 \\over 2 \\sigma^2} (x^{(k} - \\mu)^2 \\right)  \\right) \\\\\n",
    "             & = \\arg\\max \\sum_{k=1}^N \\left( \\log \\left( {1 \\over \\sqrt{2\\pi} \\sigma} \\right) - {1 \\over 2 \\sigma^2} (x^{(k} - \\mu)^2  \\right)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "함수의 최대(또는 최소)는 미분이 0 이 되는 곳으로 정의되므로,\n",
    "\n",
    "$$ {\\partial \\over \\partial \\mu} \\sum_{k=1}^N \\left( \\log \\left( {1 \\over \\sqrt{2\\pi} \\sigma} \\right) - {1 \\over 2 \\sigma^2} (x^{(k} - \\mu)^2 \\right)$$\n",
    "\n",
    "$$ = - {1 \\over 2 \\sigma^2} {\\partial \\over \\partial \\mu} \\sum_{k=1}^N \\left( x^{2(k} -2x^{(k}\\mu + \\mu^2 \\right)  = {1 \\over 2 \\sigma^2} {\\partial \\over \\partial \\mu} \\sum_{k=1}^N \\left( 2x^{(k}\\mu - \\mu^2 \\right) = 0 $$\n",
    "$$ \\Rightarrow  \\sum_{k=1}^N \\left( x^{(k} - \\mu \\right) = \\sum_{k=1}^N x^{(k} -N \\mu = 0 \\Rightarrow \\mu = {1 \\over N} \\sum_{k=1}^N x^{(k}  $$\n",
    "\n",
    "따라서 가우시안 확률밀도의 평균의 최우추정은 훈련자료의 산술 평균(매우 직관적인 결과)이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률밀도함수가 $ p(x) = \\mathscr{N}(\\mu, \\sigma)$ 로 주어진 자료  $X=\\{x^{(1},x^{(2},…,x^{(N}\\}$  에서 표준편차(σ) 와 평균(μ)의 최우추정은 변수가 두 개이므로 미분은 그래디언트가 된다.\n",
    "\n",
    "$$ \\hat{\\theta} = \\begin{bmatrix} \\theta_1 = \\mu \\\\ \\theta_2 = \\sigma^2 \\end{bmatrix}\n",
    "\\Rightarrow \\nabla_\\theta = \\begin{bmatrix} {\\partial \\over \\partial \\theta_1} \\sum_{k=1}^N \\log p(x^{(k} | \\theta) \\\\  {\\partial \\over \\partial \\theta_2} \\sum_{k=1}^N \\log p(x^{(k} | \\theta) \\end{bmatrix}\n",
    "= \\sum_{k=1}^N \\begin{bmatrix} {1 \\over \\theta_2}(x^{(k} - \\theta_1)  \\\\ -{1 \\over 2\\theta_2} + {(x^{(k} - \\theta_1)^2 \\over 2 \\theta_2^2 } \\end{bmatrix} = 0 $$\n",
    "\n",
    "\n",
    "$\\theta_1$ 과 $\\theta_2$ 에 대하여 풀면\n",
    "\n",
    "\n",
    "$$ \\hat{\\theta}_1 = { 1 \\over N} \\sum_{k=1}^N \\mathbf{x}^{(k};  \\quad \\hat{\\theta}_2 = { 1 \\over N} \\sum_{k=1}^N (x^{(k} - \\hat{\\theta}_1)^2$$\n",
    "\n",
    "따라서 분산의 최우추정은 훈련자료의 표본분산이 되며, \n",
    "\n",
    "**다변량 가우시안의 최우추정**은 **표본평균벡터**와 **표본공분산행렬**이 됨도 유사한 방법으로 보일 수 있다. \n",
    "\n",
    "\n",
    "$$ \\hat{\\mathbf{\\mu}} = { 1 \\over N} \\sum_{k=1}^N x^{(k};  \\quad \\hat{\\Sigma} = { 1 \\over N} \\sum_{k=1}^N (x^{(k} - \\hat{\\mu}) (x^{(k} - \\hat{\\mu})^T$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최우추정법에 의한 확률밀도함수의 추정\n",
    "\n",
    "이러한 추정이 얼마나 잘 된 것인지를 어떻게 알 수 있나? 통계학적 추정의 정확도를 말해주는 두 측정치 bias 와 Variance\n",
    "\n",
    "* Bias : 추정치가 실제 값에 얼마나 가까운가를 말하는 정도\n",
    "* Variance : 자료가 다를 경우 추정치가 얼마나 변화하는가를 나타내는 수치.\n",
    "\n",
    "<img src=\"images/bias-variance.png\" width=\"250\">\n",
    "\n",
    "Bias-Variance tradeoff : 하나를 감소시키기 위해서는 다른 하나를 희생해야만 함\n",
    "\n",
    "<img src=\"images/bias-variance-2.png\" width=\"450\">\n",
    "\n",
    "* **평균의 최우추정은 언바이어스드(unbiased) 추정**이다.!\n",
    "\n",
    "$$ E[\\hat{\\mu}] = E \\left[ { 1 \\over N} \\sum_{k=1}^N x_k \\right] = { 1 \\over N} \\sum_{k=1}^N E[x_k] = \\mu$$\n",
    "\n",
    "* **분산의 최우추정은 바이어스드(biased) 추정**이다. !\n",
    "\n",
    "$$ E[\\hat{\\sigma}^2] = E \\left[ { 1 \\over N} \\sum_{k=1}^N (x_k -\\hat{\\mu})^2 \\right] = \\cdots =\n",
    "{ N-1 \\over N} Var(x_k) \\ne Var(x_k)$$\n",
    "\n",
    "이는 분산의 최우추정에 진짜 평균이 아닌 최우추정 평균이 사용되기 때문이다.\n",
    "하지만 $N$ 이 무한이 증가하면, 바이어스는 제로(0)에 가까워진다. \n",
    "따라서 때때로 다음과 같은 언바이어스드 공분산을 사용한다. **다변량의 경우**에는 다음과 같이 된다.\n",
    "\n",
    "$$  \\hat{\\Sigma}_{\\text{unbiased}} = { 1 \\over N-1} \\sum_{k=1}^N (x^{(k} - \\hat{\\mu}) (x^{(k} - \\hat{\\mu})^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최우추정과 우도비검증 판별함수 시뮬레이션\n",
    "\n",
    "가우시안 분포를 이루는 데이터에 대하여 **최우추정(MLE)법**으로 우도함수의 파라미터를 추정하고, **우도비검증(LRT) 판별함수**를 이용하여 미지의 패턴을 인식하는 실습을 해보자.\n",
    "\n",
    "1. 가우시안 분포로 2-클래스를 이루는 임의의 데이터 집합을 생성한다.\n",
    "2. 주어진 데이터에서 확률밀도함수를 MLE법으로 추정한다.\n",
    "3. 추정된 확률밀도함수가 원래 확률밀도함수에 얼마나 근접한지를 확인한다.\n",
    "4. 임의의 데이터가 주어질 경우에, 이 데이터가 어느 클레스에 속하는지를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mu1 = [380, 400]\n",
    "cov1 = [[200, 0], [0, 200]]\n",
    "rv1 = sp.stats.multivariate_normal(mu1, cov1)\n",
    "X1 = rv1.rvs(200)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], s=1)\n",
    "\n",
    "mu2 = [430, 350]\n",
    "cov2 = [[240,150], [150, 240]]\n",
    "rv2 = sp.stats.multivariate_normal(mu2, cov2)\n",
    "X2 = rv2.rvs(200)\n",
    "plt.scatter(X2[:, 0], X2[:, 1], s=2)\n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "\n",
    "mu1_ = X1.mean(axis=0)\n",
    "cov1_ = np.cov(X1.T, ddof=0)\n",
    "print(mu1, mu1_)\n",
    "plt.scatter(mu1[0], mu1[1], s=60, marker='o')\n",
    "plt.scatter(mu1_[0], mu1_[1], s=60, marker='x')\n",
    "print(cov1,cov1_)\n",
    "\n",
    "mu2_ = X2.mean(axis=0)\n",
    "cov2_ = np.cov(X2.T, ddof=0)\n",
    "print(mu2, mu2_)\n",
    "plt.scatter(mu2[0], mu2[1], s=60, marker='o')\n",
    "plt.scatter(mu2_[0], mu2_[1], s=60, marker='x')\n",
    "print(cov2, cov2_)\n",
    "\n",
    "test_1 = [390, 380]\n",
    "plt.scatter(test_1[0], test_1[1], s=40, marker='^')\n",
    "test_2 = [420, 360]\n",
    "plt.scatter(test_2[0], test_2[1], s=40, marker='^')\n",
    "test_3 = [430, 370]\n",
    "plt.scatter(test_3[0], test_3[1], s=40, marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1_1 = sp.stats.multivariate_normal.pdf(test_1, mu1_, cov1_);\n",
    "result_1_2 = sp.stats.multivariate_normal.pdf(test_1, mu2_, cov2_);\n",
    "decision = \"class_1\" if result_1_1 > result_1_2 else \"class_2\"\n",
    "print( test_1,\" is\",decision )\n",
    "result_2_1 = sp.stats.multivariate_normal.pdf(test_2, mu1_, cov1_);\n",
    "result_2_2 = sp.stats.multivariate_normal.pdf(test_2, mu2_, cov2_);\n",
    "decision = \"class_1\" if result_2_1 > result_2_2 else \"class_2\"\n",
    "print( test_2,\" is\",decision )\n",
    "result_3_1 = sp.stats.multivariate_normal.pdf(test_3, mu1_, cov1_);\n",
    "result_3_2 = sp.stats.multivariate_normal.pdf(test_3, mu2_, cov2_);\n",
    "decision = \"class_1\" if result_3_1 > result_3_2 else \"class_2\"\n",
    "print(test_3,\" is\",decision )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
